import os
from google import genai

from dotenv import load_dotenv

from .base import LLMBase


class GeminiModel(LLMBase):
    """
    Gemini class for interacting with the Gemini LLM.
    This class extends the LLMBase class and implements the prompt method.
    """
    def __init__(self, model_name: str = 'gemini-pro-vision'):
        super().__init__()
        load_dotenv()

        self.client = genai.Client()
        self.model_name = model_name

        # Load Google Gemini API credentials
        #genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
        #self.model = genai.GenerativeModel(model_name)

    def prompt(self, prompt: dict) -> str:
        """
        Generate a response from the Gemini model based on the provided prompt.

        Args:
            prompt (dict): A dictionary containing the prompt details.

        Returns:
            str: The response generated by the Gemini model.
        """
        response = self.client.models.generate_content(
            model=self.model_name,
            contents=prompt,
        )
        return response.text